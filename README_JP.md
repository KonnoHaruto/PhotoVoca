# PhotoVoca

カメラで撮影した物体を自動認識し、英語の語彙学習に変換するFlutterアプリケーションです。

## 概要

PhotoVocaは、日常生活の中で目にする物体を撮影するだけで、その英語名と説明文を自動生成し、フラッシュカード形式で語彙学習ができるモバイルアプリです。Google ML Kitによる物体検出とGemini AIによる説明文生成を組み合わせることで、実用的で記憶に残りやすい学習体験を提供します。

## 主な機能

### カメラ撮影と物体認識
- リアルタイムの物体検出（Google ML Kit Object Detection）
- 撮影した物体の自動切り抜き
- 複数の物体から学習したいものを選択可能

### AI による説明文生成
- Gemini AIが物体の英語名と説明文を自動生成
- 文脈に応じた実用的な例文の提供
- 視覚的なイメージと言葉を結びつけた効果的な学習

### フラッシュカード学習
- 撮影した物体がフラッシュカードとして保存
- カードをタップして答えを確認
- スワイプで次のカードへ移動
- 学習履歴の管理

### データ管理
- SQLiteによるローカルデータベース管理
- 学習履歴の永続化
- オフラインでの学習が可能

## 技術スタック

- **フレームワーク**: Flutter 3.8.1+
- **状態管理**: Riverpod 2.5.1
- **ルーティング**: go_router 14.3.0
- **AI/ML**:
  - Google Generative AI (Gemini) 0.4.7
  - Google ML Kit Object Detection 0.14.0
- **カメラ**: camera 0.11.0+
- **データベース**: Drift (SQLite) 2.21.0
- **画像処理**: image 4.2.0

## セットアップ

### 必要な環境
- Flutter SDK 3.8.1以上
- iOS 12.0+ / Android API level 21+
- Gemini API キー

### インストール手順

1. リポジトリのクローン
```bash
git clone https://github.com/yourusername/photovoca.git
cd photovoca
```

2. 環境変数の設定
`.env`ファイルをプロジェクトルートに作成し、Gemini APIキーを設定
```
GEMINI_API_KEY=your_api_key_here
```

3. 依存関係のインストール
```bash
flutter pub get
```

4. コード生成の実行
```bash
flutter pub run build_runner build
```

5. アプリの起動
```bash
flutter run
```

## プロジェクト構成

```
lib/
├── app/              # アプリケーション設定
│   └── router.dart   # ルーティング設定
├── features/         # 機能別モジュール
│   ├── camera/       # カメラ・物体認識機能
│   ├── home/         # ホーム画面
│   └── quiz/         # クイズ・フラッシュカード機能
├── infrastructure/   # インフラ層
│   └── database/     # データベース関連
└── main.dart         # エントリーポイント
```

## 使い方

1. アプリを起動し、ホーム画面から「カメラ」を選択
2. 学習したい物体をカメラで撮影
3. 検出された物体から学習対象を選択
4. AIが生成した英語名と説明文を確認
5. 「クイズ」モードでフラッシュカード学習を開始
6. カードをタップして答えを確認し、スワイプで次へ

## 今後の開発予定

- 音声読み上げ機能の追加
- 学習進捗の可視化
- カテゴリー別の語彙管理
- 複数言語対応
- クラウド同期機能

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。

## 貢献

プルリクエストは歓迎します。大きな変更を行う場合は、まずissueを開いて変更内容について議論してください。

## お問い合わせ

ご質問や提案がある場合は、GitHubのissueページからお気軽にお問い合わせください。